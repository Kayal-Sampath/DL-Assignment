{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence_prediction_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXlRX8VMb0SW"
      },
      "source": [
        "# Text Sequence Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh72bSscp-65"
      },
      "source": [
        "**Steps involved:**\n",
        "\n",
        "1. Import necessary libaries\n",
        "\n",
        "2. Load the dataset\n",
        "3. Pre-processing: Cleaning\n",
        "4. Tokenizing : N-grams\n",
        "5. Padding: Make all sequence to a same length\n",
        "6. Model building\n",
        "    *   Embedding layer\n",
        "    *   LSTM layer\n",
        "    *   Dropout layer     \n",
        "    *   Dense \n",
        "7. Model training\n",
        "8. Prediction  of text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyF1qQsxb__9"
      },
      "source": [
        "# keras module for building LSTM \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "# set seeds for reproducability\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd6xvK5FcSlc"
      },
      "source": [
        "**Step 1: Load the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqJyOqPtpjPi"
      },
      "source": [
        "**DATASET: NEWS HEADLINES**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtIw7E0keYj0",
        "outputId": "ceeeace5-1b95-422a-c57f-ecf6e97fc34e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9TzBAqwcR3F",
        "outputId": "0ac4bdb6-4bf7-4e4e-89a1-4ecb8499d37b"
      },
      "source": [
        "curr_dir = '/content/drive/MyDrive/data/predict_text/'\n",
        "all_headlines = []\n",
        "for filename in os.listdir(curr_dir):\n",
        "    if 'Articles' in filename:\n",
        "        article_df = pd.read_csv(curr_dir + filename)\n",
        "        all_headlines.extend(list(article_df.headline.values))\n",
        "        break\n",
        "\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
        "print(\"Total no. of headlines:\",len(all_headlines))\n",
        "print()\n",
        "print(\"Sample texts:\")\n",
        "all_headlines[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of headlines: 831\n",
            "\n",
            "Sample texts:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Finding an Expansive View  of a Forgotten People in Niger',\n",
              " 'And Now,  the Dreaded Trump Curse',\n",
              " 'Venezuela’s Descent Into Dictatorship',\n",
              " 'Stain Permeates Basketball Blue Blood',\n",
              " 'Taking Things for Granted',\n",
              " 'The Caged Beast Awakens',\n",
              " 'An Ever-Unfolding Story',\n",
              " 'O’Reilly Thrives as Settlements Add Up',\n",
              " 'Mouse Infestation',\n",
              " 'Divide in G.O.P. Now Threatens Trump Tax Plan']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PTVgAb5m9X_"
      },
      "source": [
        "**Step 2: Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrFZTk4ddXMU",
        "outputId": "90d4e0d9-68d7-4cf8-9b94-1318d34fb6ce"
      },
      "source": [
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return txt \n",
        "\n",
        "corpus = [clean_text(x) for x in all_headlines]\n",
        "print(\"Before cleaning:\",all_headlines[1],\"\\nAfter cleaning:\",corpus[1],\"\\n\")\n",
        "print()\n",
        "corpus[:10]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before cleaning: And Now,  the Dreaded Trump Curse \n",
            "After cleaning: and now  the dreaded trump curse \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['finding an expansive view  of a forgotten people in niger',\n",
              " 'and now  the dreaded trump curse',\n",
              " 'venezuelas descent into dictatorship',\n",
              " 'stain permeates basketball blue blood',\n",
              " 'taking things for granted',\n",
              " 'the caged beast awakens',\n",
              " 'an everunfolding story',\n",
              " 'oreilly thrives as settlements add up',\n",
              " 'mouse infestation',\n",
              " 'divide in gop now threatens trump tax plan']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUBVmObEnAbV"
      },
      "source": [
        "**Step 3 : Tokenizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2jB7ZF7dvAc",
        "outputId": "f708e6c3-4390-4392-a20c-3f72739ebe67"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    print(\"Total number of words:\",total_words)\n",
        "    ## convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words\n",
        "\n",
        "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
        "inp_sequences[:9] #finding an expansive view  of a forgotten people in niger"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words: 2422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[169, 17],\n",
              " [169, 17, 665],\n",
              " [169, 17, 665, 367],\n",
              " [169, 17, 665, 367, 4],\n",
              " [169, 17, 665, 367, 4, 2],\n",
              " [169, 17, 665, 367, 4, 2, 666],\n",
              " [169, 17, 665, 367, 4, 2, 666, 170],\n",
              " [169, 17, 665, 367, 4, 2, 666, 170, 5],\n",
              " [169, 17, 665, 367, 4, 2, 666, 170, 5, 667]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ7hDCU-lsz4"
      },
      "source": [
        "\n",
        "Headline: finding an expansive view  of a forgotten people in niger\n",
        "\n",
        "```\n",
        "Ngram\t                                    Sequence of Tokens\n",
        "finding an\t                               [169, 17]\n",
        "finding an expansive\t                     [169, 17, 665]\n",
        "finding an expansive view                    [169, 17, 665, 367]\n",
        "finding an expansive view  of\t            [169, 17, 665, 367, 4]\n",
        "finding an expansive view  of a              [169, 17, 665, 367, 4, 2]\n",
        "finding an expansive view  of a forgotten    [169, 17, 665, 367, 4, 2, 666]\n",
        "```\n",
        "\n",
        "```\n",
        "a      --> 2\n",
        ".\n",
        ".\n",
        "an     --> 17\n",
        "fnding --> 169\n",
        ".\n",
        ".\n",
        ".\n",
        ".......-->2422\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tXfHFuqn6wF"
      },
      "source": [
        "**Step 4: Padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htt6yTcIde3c",
        "outputId": "6f378b99-7ef5-4dc0-efc7-687f437cfe3a"
      },
      "source": [
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
        "\n",
        "print(predictors[:10])\n",
        "print(max_sequence_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169  17]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169  17 665]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 169  17 665 367]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 169  17 665 367   4]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 169  17 665 367   4   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 169  17 665 367   4   2 666]\n",
            " [  0   0   0   0   0   0   0   0   0   0 169  17 665 367   4   2 666 170]\n",
            " [  0   0   0   0   0   0   0   0   0 169  17 665 367   4   2 666 170   5]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6]]\n",
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-1lkwXYn98p"
      },
      "source": [
        "**Step 5: Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB0Rd-MndheM",
        "outputId": "3fdd12ce-d9dc-410a-d9e0-297c2e695e45"
      },
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add Input Embedding Layer\n",
        "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "    \n",
        "    # Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.1))\n",
        "    \n",
        "    # Add Output Layer\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model(max_sequence_len, total_words)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 18, 10)            24220     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2422)              244622    \n",
            "=================================================================\n",
            "Total params: 313,242\n",
            "Trainable params: 313,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD2inZY7oPGB"
      },
      "source": [
        "**Step 6: Model training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwx905TpoOBg",
        "outputId": "f3df50c2-8da0-4eac-dd68-801499644aea"
      },
      "source": [
        "model.fit(predictors, label, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 4.6414\n",
            "Epoch 2/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 4.5543\n",
            "Epoch 3/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 4.4766\n",
            "Epoch 4/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 4.3998\n",
            "Epoch 5/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 4.3179\n",
            "Epoch 6/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 4.2371\n",
            "Epoch 7/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 4.1627\n",
            "Epoch 8/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 4.0827\n",
            "Epoch 9/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 4.0077\n",
            "Epoch 10/10\n",
            "151/151 [==============================] - 3s 20ms/step - loss: 3.9328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f51c53422d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au70Wt0woBX_"
      },
      "source": [
        "**Step 7 : Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEbJSKJxdmHs"
      },
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict_classes(token_list, verbose=0)\n",
        "        print(predicted)\n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOCdAqZFdsjc",
        "outputId": "667046de-8e08-486b-de3c-9128b19747b2"
      },
      "source": [
        "print (generate_text(\"united states\", 1, model, max_sequence_len))\n",
        "print (generate_text(\"united states\", 7, model, max_sequence_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[30]\n",
            "United States York\n",
            "[30]\n",
            "[3]\n",
            "[1]\n",
            "[193]\n",
            "[4]\n",
            "[1]\n",
            "[193]\n",
            "United States York To The Americans Of The Americans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZtkF0tKbuLo"
      },
      "source": [
        "# Number Sequence Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_EvFc0UZAI4"
      },
      "source": [
        "import numpy as np\n",
        "def splitSequence(seq, n_steps):\n",
        "    \n",
        "    #Declare X and y as empty list\n",
        "    X = []\n",
        "    y = []\n",
        "    \n",
        "    for i in range(len(seq)):\n",
        "        #get the last index\n",
        "        lastIndex = i + n_steps\n",
        "        \n",
        "        #if lastIndex is greater than length of sequence then break\n",
        "        if lastIndex > len(seq) - 1:\n",
        "            break\n",
        "            \n",
        "        #Create input and output sequence\n",
        "        seq_X, seq_y = seq[i:lastIndex], seq[lastIndex]\n",
        "        \n",
        "        #append seq_X, seq_y in X and y list\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "        pass\n",
        "    #Convert X and y into numpy array\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    \n",
        "    return X,y \n",
        "    \n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVkzWSy0aF44"
      },
      "source": [
        "**Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkUTkDnvY3Vw"
      },
      "source": [
        "data = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fETxGLELZDpZ",
        "outputId": "80ce8cc0-b59d-4a89-e0a5-3fcaeaca0805"
      },
      "source": [
        "n_steps = 5\n",
        "X, y = splitSequence(data, n_steps = 5)\n",
        "for i in range(len(X)):\n",
        "    print(X[i], y[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10 20 30 40 50] 60\n",
            "[20 30 40 50 60] 70\n",
            "[30 40 50 60 70] 80\n",
            "[40 50 60 70 80] 90\n",
            "[50 60 70 80 90] 100\n",
            "[ 60  70  80  90 100] 110\n",
            "[ 70  80  90 100 110] 120\n",
            "[ 80  90 100 110 120] 130\n",
            "[ 90 100 110 120 130] 140\n",
            "[100 110 120 130 140] 150\n",
            "[110 120 130 140 150] 160\n",
            "[120 130 140 150 160] 170\n",
            "[130 140 150 160 170] 180\n",
            "[140 150 160 170 180] 190\n",
            "[150 160 170 180 190] 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PED8OtxOZKDj",
        "outputId": "744461e9-cf65-4178-a531-c52a428959bc"
      },
      "source": [
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "print(X[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[10]\n",
            "  [20]\n",
            "  [30]\n",
            "  [40]\n",
            "  [50]]\n",
            "\n",
            " [[20]\n",
            "  [30]\n",
            "  [40]\n",
            "  [50]\n",
            "  [60]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H1f26JWZotX"
      },
      "source": [
        "**Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxs_TTJdZMFZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iFdNz88ZOsD",
        "outputId": "c3ac5a21-95ff-46af-b809-6b3f697d718e"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y2nA9aBZTPr"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jakvGjUfZVZK",
        "outputId": "a891aaed-d944-4626-cced-1196967d47c5"
      },
      "source": [
        "model.fit(X, y, epochs=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6422 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8574 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6014 - accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7135 - accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3957 - accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3587 - accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6168 - accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0895 - accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1798 - accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4981 - accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0935 - accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1378 - accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3661 - accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0506 - accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1665 - accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2814 - accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe68d0d7c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpWavlLoZZmp",
        "outputId": "eaedafcc-9bc6-41b2-d23d-34fb3d945e0c"
      },
      "source": [
        "test_data = np.array([90, 100, 110, 120, 130])\n",
        "test_data = test_data.reshape((1, n_steps, n_features))\n",
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 90],\n",
              "        [100],\n",
              "        [110],\n",
              "        [120],\n",
              "        [130]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WfR2cHKUQ03"
      },
      "source": [
        "**Output prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJZlkkOMZbni",
        "outputId": "dd71979c-4620-4c27-bcc0-f1e43496f893"
      },
      "source": [
        "predictNextNumber = model.predict(test_data, verbose=1)\n",
        "print(predictNextNumber)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "[[140.49368]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
